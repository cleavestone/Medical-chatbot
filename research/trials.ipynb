{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\Desktop\\Medical-chatbot-llama2\\mchatbot\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "import os\n",
    "from langchain.document_loaders import PyMuPDFLoader,PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "pinecone_key=os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=api_key\n",
    "os.environ[\"PINECONE_API_KEY\"]=pinecone_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client[grpc] in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (3.2.2)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone-client[grpc]) (2024.6.2)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.53.0 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone-client[grpc]) (1.63.2)\n",
      "Collecting grpc-gateway-protoc-gen-openapiv2==0.1.0 (from pinecone-client[grpc])\n",
      "  Using cached grpc_gateway_protoc_gen_openapiv2-0.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: grpcio>=1.59.0 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone-client[grpc]) (1.64.1)\n",
      "Requirement already satisfied: lz4>=3.1.3 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone-client[grpc]) (4.3.3)\n",
      "Collecting protobuf<3.21.0,>=3.20.0 (from pinecone-client[grpc])\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone-client[grpc]) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone-client[grpc]) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone-client[grpc]) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client[grpc]) (0.4.6)\n",
      "Using cached grpc_gateway_protoc_gen_openapiv2-0.1.0-py3-none-any.whl (12 kB)\n",
      "Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Installing collected packages: protobuf, grpc-gateway-protoc-gen-openapiv2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "Successfully installed grpc-gateway-protoc-gen-openapiv2-0.1.0 protobuf-3.20.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages\\medical_chatbot-0.0.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "protoc-gen-openapiv2 0.0.1 requires protobuf>=4.21.0, but you have protobuf 3.20.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone-client[grpc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to Pinecone server\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "pc = Pinecone()\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1'\n",
    "        ) \n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(directory):\n",
    "    loader=PyPDFDirectoryLoader(directory,glob='*.pdf')\n",
    "    data=loader.load()\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "    documents=text_splitter.split_documents(data)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Using cached pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Using cached pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TheGALE\\nENCYCLOPEDIA\\nofMEDICINE\\nSECOND EDITION'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data=load_pdf(r'C:\\Users\\Hp\\Desktop\\Medical-chatbot-llama2\\data')\n",
    "extracted_data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example, she is at higher risk for complications during preg-nancy because of a disorder or disease such as diabetes.\n",
      "However, selective reduction is recommended often in\n",
      "cases of multi-fetal pregnancy, or the presence of more thanone fetus, typically, at least three or more fetuses. In thegeneral population, multi-fetal pregnancy happens in onlyabout 1-2% of pregnant women. But multi-fetal pregnan-cies occur far more often in women using fertility drugs.\n",
      "Precautions\n"
     ]
    }
   ],
   "source": [
    "print(extracted_data[150].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_pinecone\n",
      "  Using cached langchain_pinecone-0.1.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from langchain_pinecone) (0.2.10)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from langchain_pinecone) (1.26.4)\n",
      "Collecting pinecone-client<4.0.0,>=3.2.2 (from langchain_pinecone)\n",
      "  Using cached pinecone_client-3.2.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (0.1.82)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (2.7.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_pinecone) (8.4.2)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone-client<4.0.0,>=3.2.2->langchain_pinecone) (2024.6.2)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone-client<4.0.0,>=3.2.2->langchain_pinecone) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone-client<4.0.0,>=3.2.2->langchain_pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone-client<4.0.0,>=3.2.2->langchain_pinecone) (2.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.10.5)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_pinecone) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_pinecone) (2.18.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client<4.0.0,>=3.2.2->langchain_pinecone) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_pinecone) (3.7)\n",
      "Using cached langchain_pinecone-0.1.1-py3-none-any.whl (8.4 kB)\n",
      "Using cached pinecone_client-3.2.2-py3-none-any.whl (215 kB)\n",
      "Installing collected packages: pinecone-client, langchain_pinecone\n",
      "  Attempting uninstall: pinecone-client\n",
      "    Found existing installation: pinecone-client 4.1.1\n",
      "    Uninstalling pinecone-client-4.1.1:\n",
      "      Successfully uninstalled pinecone-client-4.1.1\n",
      "Successfully installed langchain_pinecone-0.1.1 pinecone-client-3.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install langchain_pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_from_docs = PineconeVectorStore.from_documents(\n",
    "        extracted_data,\n",
    "        index_name=index_name,\n",
    "        embedding=embeddings\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Allergy and Immunology. Boston: Little, Brown and Co.,\\n1995.\\nNovick, N. L. You Can Do Something About Your Allergies.\\nNew York: Macmillan, 1994.\\nWeil, A. Natural Health, Natural Medicine: A Comprehensive\\nManual for Wellness and Self-Care. New York: Houghton\\nMifflin, 1995.\\nRichard Robinson\\nAllergies\\nDefinition\\nAllergies are abnormal reactions of the immune sys-\\ntem that occur in response to otherwise harmless sub-stances.', metadata={'page': 127.0, 'source': 'C:\\\\Users\\\\Hp\\\\Desktop\\\\Medical-chatbot-llama2\\\\data\\\\Medical_book.pdf'}), Document(page_content='Description\\nAllergies are among the most common of medical\\ndisorders. It is estimated that 60 million Americans, ormore than one in every five people, suffer from someform of allergy, with similar proportions throughoutmuch of the rest of the world. Allergy is the single largestreason for school absence and is a major source of lostproductivity in the workplace.\\nAn allergy is a type of immune reaction. Normally,', metadata={'page': 128.0, 'source': 'C:\\\\Users\\\\Hp\\\\Desktop\\\\Medical-chatbot-llama2\\\\data\\\\Medical_book.pdf'}), Document(page_content='Allergen —A substance that provokes an allergic\\nresponse.\\nAllergic rhinitis —Inflammation of the mucous\\nmembranes of the nose and eyes in response to anallergen.\\nAnaphylaxis —Increased sensitivity caused by previ-\\nous exposure to an allergen that can result in bloodvessel dilation and smooth muscle contraction.Anaphylaxis can result in sharp blood pressuredrops and difficulty breathing.\\nAngioedema —Severe non-inflammatory swelling of', metadata={'page': 133.0, 'source': 'C:\\\\Users\\\\Hp\\\\Desktop\\\\Medical-chatbot-llama2\\\\data\\\\Medical_book.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "# Ranked Results\n",
    "query=\"What are allergies\"\n",
    "docs=vectorstore_from_docs.similarity_search(query,k=3)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template\n",
    "prompt_template='''\n",
    "Use the following pieces of information to answer the users questions.\n",
    "if you dont know the answer , just say that you dont know . dont try to \n",
    "make up the answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful Answer :\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template,input_variables=[\"context\",\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RetrievalQA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m qa\u001b[38;5;241m=\u001b[39m\u001b[43mRetrievalQA\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_chain_type(\n\u001b[0;32m      2\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[0;32m      3\u001b[0m     chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mvectorstore_from_docs\u001b[38;5;241m.\u001b[39mas_retriever(),\n\u001b[0;32m      5\u001b[0m     return_source_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RetrievalQA' is not defined"
     ]
    }
   ],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=vectorstore_from_docs.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     user_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput prompt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     results\u001b[38;5;241m=\u001b[39m\u001b[43mqa\u001b[49m({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m:user_input })\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse: \u001b[39m\u001b[38;5;124m\"\u001b[39m,results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'qa' is not defined"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input=input(f'Input prompt')\n",
    "    results=qa({'query':user_input })\n",
    "    print(\"Response: \",results['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages\\medical_chatbot-0.0.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone\n",
      "  Downloading pinecone-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone) (2024.6.2)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from pinecone) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\desktop\\medical-chatbot-llama2\\mchatbot\\lib\\site-packages (from tqdm>=4.64.1->pinecone) (0.4.6)\n",
      "Downloading pinecone-4.0.0-py3-none-any.whl (214 kB)\n",
      "   ---------------------------------------- 0.0/214.4 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/214.4 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 30.7/214.4 kB 660.6 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 30.7/214.4 kB 660.6 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 102.4/214.4 kB 590.8 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 102.4/214.4 kB 590.8 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 122.9/214.4 kB 481.4 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 153.6/214.4 kB 510.2 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 163.8/214.4 kB 468.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- 214.4/214.4 kB 523.5 kB/s eta 0:00:00\n",
      "Installing collected packages: pinecone\n",
      "Successfully installed pinecone-4.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pinecone.fr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
